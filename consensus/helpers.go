package consensus

// TODO: Split this file into multiple helpers (e.g. signatures.go, hotstuff_helpers.go, etc...)
import (
	"encoding/base64"

	typesCons "github.com/pokt-network/pocket/consensus/types"
	"github.com/pokt-network/pocket/logger"
	"github.com/pokt-network/pocket/shared/codec"
	cryptoPocket "github.com/pokt-network/pocket/shared/crypto"
	"google.golang.org/protobuf/proto"
)

// These constants and variables are wrappers around the autogenerated protobuf types and were
// added to simply make the code in the `consensus` module more readable.
const (
	NewRound  = typesCons.HotstuffStep_HOTSTUFF_STEP_NEWROUND
	Prepare   = typesCons.HotstuffStep_HOTSTUFF_STEP_PREPARE
	PreCommit = typesCons.HotstuffStep_HOTSTUFF_STEP_PRECOMMIT
	Commit    = typesCons.HotstuffStep_HOTSTUFF_STEP_COMMIT
	Decide    = typesCons.HotstuffStep_HOTSTUFF_STEP_DECIDE

	Propose = typesCons.HotstuffMessageType_HOTSTUFF_MESSAGE_PROPOSE
	Vote    = typesCons.HotstuffMessageType_HOTSTUFF_MESSAGE_VOTE

	ByzantineThreshold = float64(2) / float64(3)

	HotstuffMessageContentType = "consensus.HotstuffMessage"
)

var HotstuffSteps = [...]typesCons.HotstuffStep{NewRound, Prepare, PreCommit, Commit, Decide}

// ** Hotstuff Helpers ** //

// IMPROVE: Avoid having the `ConsensusModule` be a receiver of this; making it more functional.
// TODO: Add unit tests for all quorumCert creation & validation logic...
func (m *consensusModule) getQuorumCertificate(height uint64, step typesCons.HotstuffStep, round uint64) (*typesCons.QuorumCertificate, error) {
	var pss []*typesCons.PartialSignature
	for _, msg := range m.messagePool[step] {
		if msg.GetPartialSignature() == nil {

			m.logger.Warn().Fields(
				map[string]interface{}{
					"height": msg.GetHeight(),
					"step":   msg.GetStep(),
					"round":  msg.GetRound(),
				},
			).Msg("No partial signature found which should not happen...")

			continue
		}
		if msg.GetHeight() != height || msg.GetStep() != step || msg.GetRound() != round {

			m.logger.Warn().Fields(
				map[string]interface{}{
					"height": msg.GetHeight(),
					"step":   msg.GetStep(),
					"round":  msg.GetRound(),
				},
			).Msg("Message in pool does not match (height, step, round) of QC being generated")

			continue
		}

		ps := msg.GetPartialSignature()
		if ps.Signature == nil || len(ps.Address) == 0 {

			m.logger.Warn().Fields(
				map[string]interface{}{
					"height": msg.GetHeight(),
					"step":   msg.GetStep(),
					"round":  msg.GetRound(),
				},
			).Msg("Partial signature is incomplete which should not happen...")

			continue
		}
		pss = append(pss, msg.GetPartialSignature())
	}

	if err := m.isOptimisticThresholdMet(len(pss)); err != nil {
		return nil, err
	}

	thresholdSig, err := getThresholdSignature(pss)
	if err != nil {
		return nil, err
	}

	return &typesCons.QuorumCertificate{
		Height:             height,
		Step:               step,
		Round:              round,
		Block:              m.block,
		ThresholdSignature: thresholdSig,
	}, nil
}

func (m *consensusModule) findHighQC(msgs []*typesCons.HotstuffMessage) (qc *typesCons.QuorumCertificate) {
	for _, m := range msgs {
		if m.GetQuorumCertificate() == nil {
			continue
		}
		// TODO: Make sure to validate the "highest QC" first and add tests
		if qc == nil || m.GetQuorumCertificate().Height > qc.Height {
			qc = m.GetQuorumCertificate()
		}
	}
	return
}

func getThresholdSignature(partialSigs []*typesCons.PartialSignature) (*typesCons.ThresholdSignature, error) {
	thresholdSig := new(typesCons.ThresholdSignature)
	thresholdSig.Signatures = make([]*typesCons.PartialSignature, len(partialSigs))
	copy(thresholdSig.Signatures, partialSigs)
	return thresholdSig, nil
}

func isSignatureValid(msg *typesCons.HotstuffMessage, pubKeyString string, signature []byte) bool {
	pubKey, err := cryptoPocket.NewPublicKey(pubKeyString)
	if err != nil {
		logger.Global.Warn().Err(err).Msgf("Error getting PublicKey from bytes")
		return false
	}
	bytesToVerify, err := getSignableBytes(msg)
	if err != nil {
		logger.Global.Warn().Err(err).Msgf("Error getting bytes to verify")
		return false
	}
	return pubKey.Verify(bytesToVerify, signature)
}

func (m *consensusModule) didReceiveEnoughMessageForStep(step typesCons.HotstuffStep) error {
	return m.isOptimisticThresholdMet(len(m.messagePool[step]))
}

func (m *consensusModule) isOptimisticThresholdMet(n int) error {
	numValidators := len(m.validatorMap)
	if !(float64(n) > ByzantineThreshold*float64(numValidators)) {
		return typesCons.ErrByzantineThresholdCheck(n, ByzantineThreshold*float64(numValidators))
	}
	return nil
}

func (m *consensusModule) resetForNewHeight() {
	m.round = 0
	m.block = nil
	m.highPrepareQC = nil
	m.lockedQC = nil
}

func protoHash(m proto.Message) string {
	b, err := codec.GetCodec().Marshal(m)
	if err != nil {
		logger.Global.Fatal().Err(err).Msg("Could not marshal proto message")
	}
	return base64.StdEncoding.EncodeToString(b)
}

/*** P2P Helpers ***/

func (m *consensusModule) sendToNode(msg *typesCons.HotstuffMessage) {
	// TODO(olshansky): This can happen due to a race condition with the pacemaker.
	if m.leaderId == nil {
		m.logger.Error().Msg(typesCons.ErrNilLeaderId.Error())
		return
	}

	m.logger.Info().Msg(typesCons.SendingMessage(msg, *m.leaderId))
	anyConsensusMessage, err := codec.GetCodec().ToAny(msg)
	if err != nil {
		m.logger.Error().Err(err).Msg(typesCons.ErrCreateConsensusMessage.Error())
		return
	}
	if err := m.GetBus().GetP2PModule().Send(cryptoPocket.AddressFromString(m.idToValAddrMap[*m.leaderId]), anyConsensusMessage); err != nil {
		m.logger.Error().Err(err).Msg(typesCons.ErrSendMessage.Error())
		return
	}
}

func (m *consensusModule) broadcastToNodes(msg *typesCons.HotstuffMessage) {
	m.logger.Info().Msg(typesCons.BroadcastingMessage(msg))
	anyConsensusMessage, err := codec.GetCodec().ToAny(msg)
	if err != nil {
		m.logger.Error().Err(err).Msg(typesCons.ErrCreateConsensusMessage.Error())
		return
	}
	if err := m.GetBus().GetP2PModule().Broadcast(anyConsensusMessage); err != nil {
		m.logger.Error().Err(err).Msg(typesCons.ErrBroadcastMessage.Error())
		return
	}
}

/*** Persistence Helpers ***/

// TECHDEBT: Integrate this with the `persistence` module or a real mempool.
func (m *consensusModule) clearMessagesPool() {
	for _, step := range HotstuffSteps {
		m.messagePool[step] = make([]*typesCons.HotstuffMessage, 0)
	}
}

/*** Leader Election Helpers ***/

func (m *consensusModule) isLeaderUnknown() bool {
	return m.leaderId == nil
}

func (m *consensusModule) isLeader() bool {
	return m.leaderId != nil && *m.leaderId == m.nodeId
}

func (m *consensusModule) isReplica() bool {
	return !m.isLeader()
}

func (m *consensusModule) clearLeader() {
	m.logPrefix = DefaultLogPrefix
	m.leaderId = nil
}

func (m *consensusModule) electNextLeader(message *typesCons.HotstuffMessage) error {
	leaderId, err := m.leaderElectionMod.ElectNextLeader(message)
	if err != nil || leaderId == 0 {

		m.logger.Error().Err(err).Fields(
			map[string]interface{}{
				"leaderId": leaderId,
				"height":   m.height,
				"round":    m.round,
			},
		).Msg("leader election failed: Validator cannot take part in consensus")

		m.clearLeader()
		return err
	}

	m.leaderId = &leaderId

	if m.isLeader() {
		m.setLogPrefix("LEADER")

		m.logger.Info().Fields(map[string]interface{}{
			"height": m.height,
			"round":  m.round,
			"addr":   m.idToValAddrMap[*m.leaderId],
		}).Msg("ðŸ‘‘ðŸ‘‘ðŸ‘‘ðŸ‘‘ðŸ‘‘ðŸ‘‘ I am the new leader")
	} else {
		m.setLogPrefix("REPLICA")

		m.logger.Info().Fields(map[string]interface{}{
			"height": m.height,
			"round":  m.round,
			"addr":   m.idToValAddrMap[*m.leaderId],
		}).Msg("ðŸ‘‘ Elected new leader")
	}

	return nil
}

/*** General Infrastructure Helpers ***/
func (m *consensusModule) setLogPrefix(logPrefix string) {
	logger.Global.UpdateFields(map[string]interface{}{
		"kind": logPrefix,
	})
	m.logger = logger.Global.CreateLoggerForModule("consensus")
}
